\section{Comparison to other sensing technologies}
\label{ch:sens_compare}
In order to properly place capacitive proximity sensing in the domain of smart environments it is necessary to include a comparison to other sensing technologies. I have given an overview of common technologies in Section \ref{ch:rel_sensor_tech}. The results are briefly recapitulated, in order to keep this section self-contained. 

\subsection{Overview of sensing technologies in smart environments}
% Table generated by Excel2LaTeX from sheet 'Tabelle1'
\begin{table}[htbp]
  \centering
  \footnotesize
  \caption{Qualitative comparison between capacitive proximity sensors and other senor technologies}
    \begin{tabularx}{\linewidth}{Xp{4cm}XXXX}
    \toprule
    \textbf{Name} & \textbf{Application Domains} & \textbf{Environmental Influences} & \textbf{Detection Range} & \textbf{Processing Complexity} & \textbf{Unobtrusiveness} \\
    \midrule
    \textbf{Capacitive proximity sensing} & indoor localization, smart appliances, physiological sensing, gestural interaction & electric fields, conductive objects & near distance   (< 100cm) & Few high dynamic range data sources  & invisible integration possible \\ \addlinespace
    \textbf{Capacitive touch sensing} & smart appliances, physiological sensing, gestural interaction & electric fields, conductive objects & touch  & Few binary sensors & thin cover above electrodes \\ \addlinespace
    \textbf{RGB cameras } & indoor localization, smart appliances, physiological sensing, gestural interaction & occlusion, external lights & far distance     (> 10m) & Complex image processing based on resolution & pinhole lenses \\ \addlinespace
    \textbf{Infrared cameras} & indoor localization, physiological sensing, gestural interaction & occlusion, external infrared light & medium distance (< 5m) & Complex image processing based on resolution & infrared source and camera \\ \addlinespace
    \textbf{Ultrasound sensing} & indoor localization, smart appliances, gestural interaction & acoustic occlusion, absorbing materials & medium distance (< 5m) & Few low dynamic range data sources & emitter and senders with exposed pinhole speaker, microphone \\ \addlinespace
    \textbf{Microphone arrays} & indoor localization, smart appliances, physiological sensing & environmental noise, absorbing materials & medium distance (< 5m) & Very high dynamic range data sources & exposed pinhole microphones \\ \addlinespace
    \textbf{Radiofrequency sensing} & indoor localization, smart appliances, gestural interaction & other RF devices & far distance     (> 10m) & Few low dynamic range data sources & hidden emitters and senders possible \\
    \bottomrule
    \end{tabularx}%
  \label{tab:eval_sensortech}%
\end{table}%
 
Capacitive touch sensing, as opposed to capacitive proximity sensing relies on an surface being touched instead of an object being in proximity and is ubiquitous in touch screen applications. The technology is actually very similar to capacitive proximity sensing, using the same measurement principle and similar electrode considerations. The electrodes are typically below a protective layer of non-conductive layer. However, they are tuned to detect very close proximity only. This restriction greatly increases the potential resolution in close distances.

RGB cameras are a class of image sensors operating in the same frequency domain as the human eye. They are capable of easily distinguishing different colors. The most common technologies nowadays are CMOS and CCD sensors that use specific filters to distinguish different wavelengths. They vary strongly in resolution and achievable frames per second. The major disadvantage is that they rely on external light sources and are therefore not well suited in dark environments.

Infrared cameras operate in near light frequencies that are invisible to the human eye. This allows for application in dark environments, as it is possible to project infrared light into the scene without disturbing the user. This is primarily used for illumination, but may also use particular patterns, the reflections of which can be analyzed. It uses the same type of sensors as RGB camera, while having different filters, resulting in a single channel image.

Ultrasound sensing uses low frequency range mechanical waves just above the audible limit of human hearing. The waves propagate similar to sound signals and one can perform reflection measurements or time-of-flight methods. The emitters and receivers can be easily modified to use different frequencies, thus enabling to use a number of sensors in a single setup or reduce the amount of required receivers. The systems detect most materials unless they have a strong dampening effect on mechanical waves in that frequency range.

Microphone arrays detect signals in the range of human hearing, and thus work with audible signals, such as human speech. They are typically based on piezoelectric sensors that transfer the vibration of a crystal to an electric current. The frequency ranges are associated to human hearing, thus covering at least the range between 10 Hz and 20 kHz, but often also exceeding this. Common sampling rates include 48 kHz or 96 kHz. 

Radiofrequency (RF) sensing uses signals in a range between several hundred kHz up to 5GHz, typically used for wireless communication. Commonly the signal strength or time of flight is used to gather information about the environment. This technology is very popular due to the prevalence of WiFi equipment in most modern environments, allowing to create applications based on existing hardware that can be additionally used for communication between different nodes. Other popular radio-technologies include ZigBee and Bluetooth.

A short overview can be found in Table \ref{tab:eval_sensortech}. Going back to the benchmarking model, I have included a comparison of suitable application domains, environmental influences, detection range, processing complexity and unobtrusiveness of the technology. This subset of features is a selection of the set presented in Section \ref{ch:eval} and more specifically Table \ref{tab:bench_cap_feat_weights}, but includes some more details on the particular aspects of the different sensing technologies related to the given feature.

\subsection{Classification of capacitive proximity sensors}
Most technologies are capable of supporting multiple application domains. Some non-intuitive examples include WiSee that enables whole-body gestural interaction using WiFi signals \cite{pu2013whole} or TapSense that uses a single microphone to enable gesture interfaces on various surfaces \cite{harrison2011tapsense}. 

Capacitive sensors are disturbed by conductive objects and electric fields, whereas cameras struggle with occlusion and additional light sources. A line of sight is required, even though some materials, such as glass have different opacity properties for the different wavelengths, in this case blocking infrared light. Some plastics however will block visible light, while infrared passes through. Acoustic sensors are prone to dampening materials and environmental noise interfering with the signal. Similar to cameras a multitude of sensors can be used to filter out environmental noise or locate the source of a specific signal. Radiofrequency signals usually propagate well through most materials. There is a dampening effect, particularly for high-frequency ranges and weak signals, obvious in a reduced reception indoors. Additionally, conductive objects may create a shield, significantly reduce the measurable effect of outside external fields. In the common WiFi frequency bands of 2.4 GHz and 5 GHz a multitude of devices are communication, leading to a limitation of potential bandwidth and potential interference. This has to be considered when designing applications for this sensor category. 

Regarding the detection range mostly applications in buildings are considered. Here it is not usually necessary to measure properties of objects that are very far away, e.g. more than 10 m. In this criterion deteriorating sensor readings at a certain distance also have to be considered. One example is radiofrequency sensing that has the best range, but considerable limitations when being applied over short distances. The fast signal propagation makes it difficult to measure the time-of-flight without specialized hardware. Visible light cameras have to consider the required distance in design of the optics. However, it is possible to use adaptive optics to enable a higher range in suitable distances. Infrared cameras have deteriorating quality, particularly when using static pattern projection, limiting their range to a fairly short interval. Some additions include using stereo infrared cameras, or adaptive projection patterns. Ultrasound also gets less precise when exceeding a certain distance, due to the wave properties and single measurements. However, the slower propagation makes it suitable for applications at close distances. Capacitive proximity sensors struggle to measure objects that are far away from the sensing electrode, as their influence on the electric field might be below the achievable resolution. Specific layouts of electrodes allow very precise measurements at small distances.

It is not trivial to find a good measure for the processing complexity associated to different sensing technologies. An approach is to take the dynamic range of a sensor and the number of sensors typically required. Dynamic range is the difference between the smallest detectable value and the largest detectable value. Microphones have a high dynamic range measuring over a larger frequency scale, whereas touch sensors only have two different states. Ultrasound usually measures simple amplitudes in time-of-flight systems and thus does not require complex processing. Image processing in both visible and infrared domains requires complex operations on large data arrays and is difficult to integrate in simple embedded systems. This discrepancy has a distinct influence on the number of sensor systems required in a system. Whereas, a single touch sensor is required on each position that is supposed to be interactive, using a single camera can account for watching a larger area, identifying numerous activities, or detecting fine activity information at a short distance. Capacitive proximity sensors have a high dynamic range for single sensors. However, as the electrodes need a certain size to enable detection at a higher distance, the number of sensors in a single setup is limited. Thus, unless complex processing methods are used the complexity can be considered low.

Regarding unobtrusiveness, capacitive sensors and RF sensors can be applied completely invisible, below any non-conductive material. Cameras, microphones and ultrasound need a direct line-of-sight or mechanical connection to the measured property and are thus more difficult to hide. As previously mentioned, certain plastics are transparent for infrared light and glass can be designed to provide varying transparency levels for different directions. Microphones can pick up any environmental noise and can be hidden below a surface that transmits mechanical waves well. One example is the CapTap prototype (\ref{ch:prot_captap}) that uses a microphone to detect acoustic events on a surface. Of the presented technologies capacitive proximity senors are the least obtrusive. The layer between object to be detected and electrode can be very thick, as shown in the Smart Bed system (\ref{ch:prot_smartbed}), having a thick mattress layer.

The actual performance of a specific sensor is difficult to assess from this limited selection of criteria and often is highly depending on the selected application. Having worked with a number of different prototypes and analyzing the advantages and disadvantages of the different technologies it is possible to build a set of benefits and limitations of capacitive proximity that will be presented in the following two sections.
